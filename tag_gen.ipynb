{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06880719",
   "metadata": {},
   "source": [
    "# This should take\n",
    "- an epitope list (consisting of ID, amino acid sequence) of length _n_\n",
    "- a _k_ to generate\n",
    "- an inter-epitope linker (amino acid, hard code for now)\n",
    "- a scaffold-epitope linker (amino acid; hard code)\n",
    "- account for specified ORF?\n",
    "\n",
    "## some math stuff\n",
    "- _n_ choose _k_ without replacement\n",
    "# output\n",
    "- a list of epitope_IDS (i.e. ID-ID-ID), Xmas insert to be cloned into GFP -- the gBlock, basically\n",
    "- the final GFP-epitope structure for each\n",
    "- check that final structure does not exceed AAV payload (section between ITRs)\n",
    "## bonus items\n",
    "- codon optimization\n",
    "- a snapgene/DNA scaffold\n",
    "- restriction cloning mimc\n",
    "\n",
    "# some biology stuff, i.e. order of events\n",
    "For TBD reasons, DNAchisel doesn't work on OsX for conda istall (with no visible errors). Probably a version issue, but ?",
    "Workflow is:\n",
    "1. AA: epitope combos + appropriate linkers\n",
    "2. codon-optimize (mus musculus, avoid EcoRI + BsrGI sites) to DNA seq\n",
    "3. Add cloning tails (known; identical) with primer length?\n",
    "    primers can come from main GFP\n",
    "4. Output gBlock sequences (how does Genscript want these?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b52d167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c8c1e8b",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def rSubset(arr, r):\n",
    "    '''return list of all subsets from an array of length r - i.e. from array choose k'''\n",
    "    # return list of all subsets of length r\n",
    "    # to deal with duplicate subsets use \n",
    "    # set(list(combinations(arr, r)))\n",
    "    return list(combinations(arr, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5499bc36",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def triplicator(epitope_sets, repeats=1):\n",
    "    '''takes a list of single epitopes and generates aa amino acid with # linkrs'''\n",
    "    triple_set = []\n",
    "    for ep in epitope_sets:\n",
    "        new_ep = [(ep) for _ in range(3)]\n",
    "        triple_set.append(new_ep)\n",
    "    return triple_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "522ae7c9",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def makeTag(epitope_sets, linker=None, prepend_linker=None, append_linker=None):\n",
    "    '''from a list of tuples, combine name sets + epitope sets with specified inter-epitope.\n",
    "    just some string manip, basically.\n",
    "    shuffles multi-epitope n choose k setups\n",
    "    if a prepend is supplied, will add the specified prepend'''\n",
    "    # collector of new things\n",
    "    knockin = [] #the tag we're knocking in\n",
    "    \n",
    "    # loop the old things\n",
    "    for epitope_set in epitope_sets:\n",
    "        # construct name and seq into new lists\n",
    "        name = []\n",
    "        seq = []\n",
    "        \n",
    "        #shuffler to avoid bias in epitope success\n",
    "        to_shuffle = list(epitope_set)\n",
    "        random.shuffle(to_shuffle) \n",
    "        epitope_set = tuple(to_shuffle)\n",
    "        \n",
    "        # make array\n",
    "        for i in range(len(epitope_set)):\n",
    "            name.append(epitope_set[i][0].replace(' ',''))\n",
    "            seq.append(epitope_set[i][1].strip(' '))\n",
    "\n",
    "        # construct final name and sequence and append\n",
    "        name = f'_'.join(name) # name that puppy\n",
    "        seq = f'{linker}'.join(seq) #make the tag sequence\n",
    "        \n",
    "        if prepend_linker:\n",
    "            seq = prepend_linker + seq\n",
    "        if append_linker:\n",
    "            seq = seq + append_linker\n",
    "        knockin.append((name, seq)) #add to array\n",
    "\n",
    "    # return new things as a dictionary\n",
    "    return dict(knockin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2cb8617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "interEp = \"GGSGGS\" #[GGS]2. for in between epitopes\n",
    "interScaffEp = \"GGSGGS\" #linker between eGFP end and beginning of tag\n",
    "\n",
    "preEpitopee =\"ggacgagctgtacaag\" #end of eGFP with BsrGI site\n",
    "endEpitopes = \"taagaattcgatatcaag\" #stop codon + EcoRI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6df98031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_list(csv, columns = None):\n",
    "    '''returns records of name + aa seq'''\n",
    "    epitopes = pd.read_csv(csv)\n",
    "    records = epitopes[columns].to_records(index=False)\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e289e655",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmas_list = read_list('xmas-in-july_tagSet.csv', columns = ['Name', 'AA seq'])\n",
    "all_list = read_list('xmas-in-july_tagSet.csv', columns = ['Name', 'AA seq'])\n",
    "jun_list = read_list('Human Protein Atlas - under 40 AAs.csv', columns = ['Antibody','Antigen Sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "594637c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmas_sets = rSubset(xmas_list, 3)\n",
    "singlets = rSubset(all_list,1)\n",
    "triplicates = triplicator(all_list,3)\n",
    "jun_triplicates = triplicator(jun_list,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1761ca81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knockin_list = [xmas_sets, singles, triplicates, jun_triplicates]\n",
    "# for item in knockin_list:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ab04549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xmas_Tags = makeTag(xmas_sets, interEp,\"GGSGGS\") #make amino acid combinations\n",
    "singlet_Tags = makeTag(singlets, interEp,\"GGSGGS\") #make amino acid combinations\n",
    "triplet_Tags = makeTag(triplicates, interEp, \"GGSGGS\")\n",
    "jun_Tags = makeTag(jun_triplicates, interEp, \"GGSGGS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f937479",
   "metadata": {},
   "source": [
    "# notes\n",
    "x shuffle to avoid biasing\n",
    "- add additional tags not covered in july\n",
    "x jun's "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
