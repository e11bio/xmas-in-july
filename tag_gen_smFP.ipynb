{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06880719",
   "metadata": {},
   "source": [
    "# This should take\n",
    "- an epitope list (consisting of ID, amino acid sequence) of length _n_\n",
    "- a _k_ to generate\n",
    "- an inter-epitope linker (amino acid, hard code for now)\n",
    "- a scaffold-epitope linker (amino acid; hard code)\n",
    "- account for specified ORF?\n",
    "\n",
    "## some math stuff\n",
    "- _n_ choose _k_ without replacement\n",
    "# output\n",
    "- a list of epitope_IDS (i.e. ID-ID-ID), Xmas insert to be cloned into GFP -- the gBlock, basically\n",
    "- the final GFP-epitope structure for each\n",
    "- check that final structure does not exceed AAV payload (section between ITRs)\n",
    "## bonus items\n",
    "- codon optimization\n",
    "- a snapgene/DNA scaffold\n",
    "- restriction cloning mimc\n",
    "\n",
    "# some biology stuff, i.e. order of events\n",
    "For TBD reasons, DNAchisel doesn't work on OsX for conda istall (with no visible errors). Probably a version issue, but ?Workflow is:\n",
    "1. AA: epitope combos + appropriate linkers\n",
    "2. codon-optimize (mus musculus, avoid EcoRI + BsrGI sites) to DNA seq\n",
    "3. Add cloning tails (known; identical) with primer length?\n",
    "    primers can come from main GFP\n",
    "4. Output gBlock sequences (how does Genscript want these?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b52d167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import random\n",
    "from dnachisel import *\n",
    "from datetime import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Bio import SeqIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93e30d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'220526'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today_str = dt.now().strftime(\"%y%m%d\") # happy autodate generator!\n",
    "today_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c8c1e8b",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def rSubset(arr, k):\n",
    "    '''Return list of all unique subsets from an array of length  - i.e. from n choose k'''\n",
    "    # return list of all subsets of length r\n",
    "    # to deal with duplicate subsets use \n",
    "    # set(list(combinations(arr, r)))\n",
    "    return list(combinations(arr, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5499bc36",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def triplicator(epitope_sets, repeats=1):\n",
    "    '''From a list of epitopes, generates the AA sequence with linkers in x repeat'''\n",
    "    triple_set = []\n",
    "    for ep in epitope_sets:\n",
    "        new_ep = [(ep) for _ in range(3)]\n",
    "        triple_set.append(new_ep)\n",
    "    return triple_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "522ae7c9",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def makeTag(epitope_sets, linker=None, prepend_linker=None, append_linker=None):\n",
    "    '''from a list of tuples, combine name sets + epitope sets with specified inter-epitope.\n",
    "    just some string manip, basically.\n",
    "    shuffles multi-epitope n choose k setups\n",
    "    if a prepend is supplied, will add the specified prepend'''\n",
    "    # collector of new things\n",
    "    knockin = [] #the tag we're knocking in\n",
    "    \n",
    "    # loop the old things\n",
    "    for epitope_set in epitope_sets:\n",
    "        # construct name and seq into new lists\n",
    "        name = []\n",
    "        seq = []\n",
    "        \n",
    "        #shuffler to avoid bias in epitope success\n",
    "        to_shuffle = list(epitope_set)\n",
    "        random.shuffle(to_shuffle) \n",
    "        epitope_set = tuple(to_shuffle)\n",
    "        \n",
    "        # make array\n",
    "        for i in range(len(epitope_set)):\n",
    "            name.append(epitope_set[i][0].replace(' ',''))\n",
    "            seq.append(epitope_set[i][1].strip(' '))\n",
    "\n",
    "        # construct final name and sequence and append\n",
    "        name = f'-'.join(name) # name that puppy\n",
    "        seq = f'{linker}'.join(seq) #make the tag sequence\n",
    "        \n",
    "        if prepend_linker:\n",
    "            seq = prepend_linker + seq\n",
    "        if append_linker:\n",
    "            seq = seq + append_linker\n",
    "        knockin.append((name, seq)) #add to array\n",
    "\n",
    "    # return new things as a dictionary\n",
    "    return dict(knockin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6df98031",
   "metadata": {
    "code_folding": [
     0,
     6,
     9
    ]
   },
   "outputs": [],
   "source": [
    "def fetchRead_list(csv, columns = None, return_df = False):\n",
    "    '''Takes a base fn (EXPLICIT LOCATION) and saves it as today's working file locally'''\n",
    "    epitopes = pd.read_csv(csv)\n",
    "    csv_title = f\"{today_str}_epitope-set.csv\"\n",
    "    epitopes.to_csv(csv_title)\n",
    "    print(\"Saved {} to file\".format(csv_title))\n",
    "    if not return_df:\n",
    "        records = epitopes[columns].to_records(index=False)\n",
    "        return records\n",
    "    if return_df:\n",
    "        return epitopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb2ecf89",
   "metadata": {
    "code_folding": [
     0,
     5
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def apply_block1(bit):\n",
    "    '''hardcoded c-myc style n terminal gen'''\n",
    "    return '{0}a{0}a{0}agvs'.format(bit) # smfp myc n terminal\n",
    "\n",
    "\n",
    "def apply_block2(bit):\n",
    "    'hardcoded c-myc style internal loop gen'''\n",
    "    return 'gga{0}aa{0}gggg{0}aa{0}agg'.format(bit) #smfp myc internal\n",
    "\n",
    "\n",
    "def apply_block3(bit):\n",
    "    '''hardcoded c-myc style c terminal gen'''\n",
    "    return 'ga{0}a{0}a{0}'.format(bit) #smfp myc c terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ec69d93",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def block_wrapper(s, bit_name):\n",
    "    bit = s[bit_name]\n",
    "    s['n-term'] = apply_block1(bit)\n",
    "    s['internal-loop'] = apply_block2(bit)\n",
    "    s['c-term'] = apply_block3(bit)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58a17de6",
   "metadata": {
    "code_folding": [
     0,
     3
    ]
   },
   "outputs": [],
   "source": [
    "def seq_joiner(df, cols:list, final = \"final_seq\"):\n",
    "    '''concatenates columns from cols in order presented'''\n",
    "    df[final]= \"\"\n",
    "    for col in cols:\n",
    "        df[final] = df[final] + str(df[col])\n",
    "    return df[final]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56c89c54",
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 220526_epitope-set.csv to file\n"
     ]
    }
   ],
   "source": [
    "#epitope list\n",
    "smfp = fetchRead_list('~/Google Drive/Shared drives/e11 Bio/Research/Lab notebooks/KL - notebook/Records Repositories/220525_epitopeTable.csv',\n",
    "                      ['Epitope', 'AA seq'], True)[['Epitope', 'AA seq']]\n",
    "#gfp bits (darkened chromophore)\n",
    "gfp_p1 =  'KGEELFTGVVPILVELDGDVNGHKFSVRGEGEGDATNGKLTLKFICTTGKLPVPWPTLVTTLGGGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTISFKDDGTYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNFNSHNVYITADKQKNGIKANFKIRHNVE'.lower()\n",
    "gfp_p2 = 'DGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSVLSKDPNEKRDHMVLLEFVTAAGITLGMDELYK'.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f8f35ff",
   "metadata": {
    "code_folding": [
     5,
     11
    ]
   },
   "outputs": [],
   "source": [
    "# make insert sequence (AA)\n",
    "smfp = smfp.apply(lambda x: block_wrapper(\n",
    "    x, 'AA seq'), axis=1)  # make epitope blocks\n",
    "smfp[['gfp1', 'gfp2']] = [gfp_p1, gfp_p2]  # add gfp sequences\n",
    "\n",
    "concat_order = ['n-term',\n",
    "                'gfp1',\n",
    "                'internal-loop',\n",
    "                'gfp2',\n",
    "                'c-term'] #order to join columns\n",
    "namer = \"\" #blank holder\n",
    "for el in concat_order:\n",
    "    namer = f\"{namer}{el}_\" #makethe name\n",
    "smfp[namer] = smfp.apply(lambda x: seq_joiner(x, concat_order), axis=1) #join the seqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0837761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "smfp['block_name'] = \"smFP-10plex-1bit_\" + smfp[['Epitope']] + \"_insert\"\n",
    "\n",
    "cols = list(smfp.columns)\n",
    "cols.insert(0, cols.pop()) #hate in place!!!\n",
    "cols.insert(1,cols.pop())\n",
    "\n",
    "smfp = smfp[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32f71dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagType = \"smfp\"\n",
    "dfs = [smfp]\n",
    "\n",
    "for df in dfs:\n",
    "    nameSave = \"singleBit\"\n",
    "    name = f'{today_str}_{nameSave}-{tagType}_AA'\n",
    "    df.to_excel((f'{name}.xlsx'))\n",
    "    df.to_csv((f'{name}.csv'), index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2cb8617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interEp = \"GGT GGC AGC GGC GGT TCT\".replace(\" \",\"\") #[GGS]2. for in between epitopes\n",
    "\n",
    "# # GGT GGC AGC GGC GGT TCT -- GGS GGS. need to test for hairpins.\n",
    "# interScaffEp = \"GGT GGC AGC GGC GGT TCT\".replace(\" \",\"\") #linker between eGFP end and beginning of tag\n",
    "\n",
    "# preEpitope =\"ggacgagctgtacaag\" #end of eGFP with BsrGI site\n",
    "# endEpitope = \"taagaattcgatatcaag\" #stop codon + EcoRI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d54e3d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e289e655",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m all_list \u001b[38;5;241m=\u001b[39m \u001b[43mread_list\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m220419_good-epitopes.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAA seq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m xmas_list \u001b[38;5;241m=\u001b[39m read_list(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxmas-in-july_tagSet.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAA seq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'read_list' is not defined"
     ]
    }
   ],
   "source": [
    "# all_list = read_list('220419_good-epitopes.csv', columns = ['Name', 'AA seq'])\n",
    "# xmas_list = read_list('xmas-in-july_tagSet.csv', columns = ['Name', 'AA seq'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35a3cee9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xmas_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m xmas_sets \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxmas\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m----> 2\u001b[0m              rSubset(\u001b[43mxmas_list\u001b[49m, \u001b[38;5;241m3\u001b[39m)]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xmas_list' is not defined"
     ]
    }
   ],
   "source": [
    "# xmas_sets = ['xmas',\n",
    "#              rSubset(xmas_list, 3)] #combo subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "594637c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xmas_sets = ['xmas',\n",
    "#              rSubset(xmas_list, 3)] #combo subset\n",
    "# singlets = ['singlets',\n",
    "#             rSubset(all_list,1)] # just easy\n",
    "# triplicates = ['triplicates',\n",
    "#                triplicator(all_list,3)]\n",
    "# jun_triplicates = ['HPA_set',\n",
    "#                    triplicator(jun_list,3)]\n",
    "\n",
    "# tagSets = [xmas_sets, singlets, triplicates, jun_triplicates] # put these together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a662255",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xmas_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m xmas_sets \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxmas\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m----> 2\u001b[0m              rSubset(\u001b[43mxmas_list\u001b[49m, \u001b[38;5;241m3\u001b[39m)] \u001b[38;5;66;03m#combo subset\u001b[39;00m\n\u001b[1;32m      3\u001b[0m tagSets \u001b[38;5;241m=\u001b[39m [xmas_sets]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xmas_list' is not defined"
     ]
    }
   ],
   "source": [
    "# xmas_sets = ['xmas',\n",
    "#              rSubset(xmas_list, 3)] #combo subset\n",
    "# tagSets = [xmas_sets] # put these together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53735bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(xmas_sets[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c9f852",
   "metadata": {
    "code_folding": [
     6
    ]
   },
   "outputs": [],
   "source": [
    "# columns = ['seq_name', 'seq_DNA']\n",
    "# df = pd.DataFrame(columns = columns)\n",
    "\n",
    "\n",
    "# tagType = \"c-terminal\"\n",
    "\n",
    "# for tagSet in tagSets:\n",
    "#     nameSave = tagSet[0]\n",
    "#     tagDict = makeTag(tagSet[1],interEp, interScaffEp) #make amino acid sequences    \n",
    "#     df = pd.DataFrame(tagDict.items(), columns = columns)\n",
    "#     df['prepend_DNA'] = preEpitope\n",
    "#     df['append_DNA'] = endEpitope\n",
    "#     df['final_synthesis'] = df['prepend_DNA'] + df['seq_DNA'] + df['append_DNA']\n",
    "#     df.to_excel((f'{today_str}_{nameSave}-{tagType}_choose3_DNA.xlsx'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baf57e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['len_insert'] = df.seq_aa.str.len()*3\n",
    "df['len_block'] = df.final_synthesis.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b22062",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "df['len_block'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acd387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "records1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb59eeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7eb073b9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abd1257",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in candidate_df['seq_name']:\n",
    "    if i in records1:\n",
    "        SeqIO.write(records1[i], output_handle1, 'fasta')\n",
    "    elif i in records2:\n",
    "        SeqIO.write(records2[i], output_handle1, 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fd741a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('c-terminal-tags.xlsx')\n",
    "# save the excel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceea1c8d",
   "metadata": {},
   "source": [
    "# removing cut sites\n",
    "\n",
    "This is very hacky and ugly, but taking the IDT generated codon opt and checking for BsrGI + EcoRI sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c691b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = pd.read_excel('c-terminal-tags_codonOptimized.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc3efbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloning_RE = [EnzymeSitePattern(\"BsrGI\"), EnzymeSitePattern(\"EcoRI\")]\n",
    "\n",
    "cloning_RE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e742fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs['BsrGI-site'] = seqs['IDT optimized'].str.contains((\"TGTACA\"))\n",
    "seqs['EcoRI-site'] = seqs['IDT optimized'].str.contains((\"GAATTC\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f06e794",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs.to_excel('flagged.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f4e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem = DnaOptimizationProblem(\n",
    "#     sequence=\"tgtacaGGAGGCTCCGGtgtacaAGGTTCTACCGATTTTTACCTTAAGGAATTC\",\n",
    "#     objectives=[\n",
    "#         AvoidPattern(\"TGTACA\"), #EcoRI - hacky but oh well, can write iterator later\n",
    "#         AvoidPattern(cloning_RE[1]), #BsrGI\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# # SOLVE THE CONSTRAINTS, OPTIMIZE WITH RESPECT TO THE OBJECTIVE\n",
    "\n",
    "# problem.resolve_constraints()\n",
    "# problem.optimize()\n",
    "\n",
    "# # PRINT SUMMARIES TO CHECK THAT CONSTRAINTS PASS\n",
    "\n",
    "# print(problem.constraints_text_summary())\n",
    "# print(problem.objectives_text_summary())\n",
    "# print(problem.sequence_before)\n",
    "# print(problem.sequence)\n",
    "# # GET THE FINAL SEQUENCE (AS STRING OR ANNOTATED BIOPYTHON RECORDS)\n",
    "\n",
    "# final_sequence = problem.sequence  # string\n",
    "# final_record = problem.to_record(with_sequence_edits=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ca82b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ef601a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da082f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # \n",
    "### basically it would be nice to call things \"GGS-Flagx3\" rather than flag flag flag but too bad\n",
    "# something breaks when _ or - are in the name\n",
    "# probably needs regex but lil clean up for names\n",
    "\n",
    "# # initializing string \n",
    "# test_str = \"HPA052507-HPA052507HPA052507\"\n",
    "  \n",
    "# # printing original string \n",
    "# print(\"The original string is : \" + test_str)\n",
    "  \n",
    "# # using list slicing + find()\n",
    "# # Check if string repeats itself\n",
    "# res = None\n",
    "# temp = (test_str + test_str).find(test_str, 1, -1)\n",
    "# if temp != -1:\n",
    "#     res = test_str[:temp]\n",
    "\n",
    "# print(res)\n",
    "# # print(\"The root substring of string : \" + res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085c7fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aae18e67",
   "metadata": {},
   "source": [
    "# codon optimization o'clock\n",
    "- avoid BsrGI + EcoRI\n",
    "- optimize for Mus musculus\n",
    "- append cloning tails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e689b104",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = triplet_Tags['FLAG_FLAG_FLAG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1fad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloning_RE = [EnzymeSitePattern(\"BsrGI\"), EnzymeSitePattern(\"EcoRI\")]\n",
    "cloning_RE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48b72d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(seq):\n",
    "    start_seq = reverse_translate(test,\n",
    "                                  randomize_codons=True,\n",
    "                                  table = 'Standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21889b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "problem = DnaOptimizationProblem(\n",
    "    sequence=seq_test,\n",
    "    constraints=[\n",
    "        AvoidPattern(cloning_RE[0]), #EcoRI - hacky but oh well, can write iterator later\n",
    "        AvoidPattern(cloning_RE[1]), #BsrGI\n",
    "    ],\n",
    "    objectives=[CodonOptimize(species='m_musculus_domesticus')]\n",
    ")\n",
    "\n",
    "# SOLVE THE CONSTRAINTS, OPTIMIZE WITH RESPECT TO THE OBJECTIVE\n",
    "\n",
    "problem.resolve_constraints()\n",
    "problem.optimize()\n",
    "\n",
    "# PRINT SUMMARIES TO CHECK THAT CONSTRAINTS PASS\n",
    "\n",
    "print(problem.constraints_text_summary())\n",
    "print(problem.objectives_text_summary())\n",
    "\n",
    "# GET THE FINAL SEQUENCE (AS STRING OR ANNOTATED BIOPYTHON RECORDS)\n",
    "\n",
    "final_sequence = problem.sequence  # string\n",
    "final_record = problem.to_record(with_sequence_edits=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d4cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da3610a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
